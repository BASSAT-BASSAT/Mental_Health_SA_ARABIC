{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First of all I will make my own synthetic data set to try on in arabic","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Data \n#create balanced data so no one label  overrules the others\ndata = [\n    {\"text\": \"Ø£Ù†Ø§ Ù…Ø®Ù†ÙˆÙ‚ ÙˆÙ…Ø´ Ù‚Ø§Ø¯Ø± Ø£ØªÙ†ÙØ³\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯ ÙˆÙ…Ø´ Ù„Ø§Ù‚ÙŠ Ø£ÙŠ Ø£Ù…Ù„\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ø¶Ø§ÙŠØ¹ ÙˆÙ…Ø­Ø¯Ø´ ÙØ§Ù‡Ù…Ù†ÙŠ\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹ÙŠØ´ ÙƒØ¯Ù‡ ÙƒØªÙŠØ±\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ù‚Ø§Ø¯Ø± Ø£ÙˆØ§Ø¬Ù‡ Ø§Ù„Ø­ÙŠØ§Ø© Ø¯ÙŠ\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ÙˆØ­ÙŠØ¯ ÙˆØ¨Ø¹ÙŠØ¯ Ø¹Ù† ÙƒÙ„ Ø­Ø§Ø¬Ø©\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø´Ø§Ø¹Ø±ÙŠ\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø­Ø§ØµØ± ÙˆÙ…Ø´ Ø¹Ø§Ø±Ù Ø£Ø·Ù„Ø¹\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹Ø¨Ø± Ø¹Ù† Ø§Ù„Ù„ÙŠ Ø¬ÙˆØ§ÙŠØ§\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ØªØ¹Ø¨Ø§Ù† Ù†ÙØ³ÙŠØ§Ù‹ ÙˆÙ…Ø´ Ù‚Ø§Ø¯Ø± Ø£ÙƒÙ…Ù„\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø­Ø·Ù… Ù…Ù† Ø¬ÙˆØ§ÙŠØ§\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ­Ù…Ù„ Ø§Ù„ÙˆØ¬Ø¹ Ø§Ù„Ù†ÙØ³ÙŠ\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø³Ù„Ø¨ÙŠØ©\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ÙØ§Ø´Ù„ ÙÙŠ ÙƒÙ„ Ø­Ø§Ø¬Ø©\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ø·Ù‰ Ø§Ù„Ù„ÙŠ Ù…Ø±ÙŠØª Ø¨ÙŠÙ‡\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹ÙŠØ´\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø³ÙŠØ·Ø± Ø¹Ù„Ù‰ Ù‚Ù„Ù‚ÙŠ\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ÙŠÙ‚\", \"label\": \"Distressed\"},\n    {\"text\": \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø¥Ø­Ø¨Ø§Ø·\", \"label\": \"Distressed\"},\n    {\"text\": \"Ø£Ù†Ø§ Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯\", \"label\": \"Distressed\"},\n\n    # Non-distressed examples\n    {\"text\": \"Ø£Ù†Ø§ ÙƒÙˆÙŠØ³ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡\", \"label\": \"Non-distressed\"},\n    {\"text\": \"ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ ÙˆÙ…ÙÙŠØ´ Ø­Ø§Ø¬Ø© ØªÙ‚Ù„Ù‚\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù‡Ø§Ø¯ÙŠ ÙˆÙ…Ø±ÙŠØ­\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¨Ø±Ø§Ø­Ø© ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø£Ù…Ù„ ÙˆÙØ±Ø­\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ø¨Ø®ÙŠØ± ÙˆØ¨Ø¹ÙŠØ´ ÙŠÙˆÙ… Ø¬Ù…ÙŠÙ„\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ø¹Ø§Ø¯ÙŠ ÙˆÙ…Ø´ Ø­Ø§Ø³Ø³ Ø¨Ø£ÙŠ Ø¶ØºØ·\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· ÙˆÙ…Ø±ØªØ§Ø­\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø·Ø§Ù‚Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù‚ÙˆÙŠ ÙˆÙ‚Ø§Ø¯Ø± Ø£ØªØ®Ø·Ù‰ Ø£ÙŠ Ø­Ø§Ø¬Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† ØªÙØ§Ø¤Ù„\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· Ø¨Ø§Ù„Ù„ÙŠ Ø­ÙˆØ§Ù„ÙŠØ§\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø­Ø¨ ÙˆØ³Ø¹Ø§Ø¯Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø±ØªØ§Ø­ Ø§Ù„Ø¨Ø§Ù„\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ù†Ø¬Ø§Ø­Ø§Øª ØµØºÙŠØ±Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…ØªÙØ§Ø¦Ù„ Ø¨Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ù„Ø­Ø¸Ø§Øª Ø¬Ù…ÙŠÙ„Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· Ø¨Ø§Ù„Ø­ÙŠØ§Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† ØªÙØ§ØµÙŠÙ„ Ø³Ø¹ÙŠØ¯Ø©\", \"label\": \"Non-distressed\"},\n    {\"text\": \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø±ØªØ§Ø­ ÙˆÙ…ØªÙØ§Ø¦Ù„\", \"label\": \"Non-distressed\"},\n]\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(df)\n\n\n# Save to CSV \ndf.to_csv(\"sentiments_data.csv\", index=False, encoding=\"utf-8-sig\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:03.570140Z","iopub.execute_input":"2025-01-19T03:32:03.570405Z","iopub.status.idle":"2025-01-19T03:32:03.956392Z","shell.execute_reply.started":"2025-01-19T03:32:03.570385Z","shell.execute_reply":"2025-01-19T03:32:03.955590Z"}},"outputs":[{"name":"stdout","text":"                                   text           label\n0              Ø£Ù†Ø§ Ù…Ø®Ù†ÙˆÙ‚ ÙˆÙ…Ø´ Ù‚Ø§Ø¯Ø± Ø£ØªÙ†ÙØ³      Distressed\n1        Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯ ÙˆÙ…Ø´ Ù„Ø§Ù‚ÙŠ Ø£ÙŠ Ø£Ù…Ù„      Distressed\n2            Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ø¶Ø§ÙŠØ¹ ÙˆÙ…Ø­Ø¯Ø´ ÙØ§Ù‡Ù…Ù†ÙŠ      Distressed\n3                 Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹ÙŠØ´ ÙƒØ¯Ù‡ ÙƒØªÙŠØ±      Distressed\n4               Ù…Ø´ Ù‚Ø§Ø¯Ø± Ø£ÙˆØ§Ø¬Ù‡ Ø§Ù„Ø­ÙŠØ§Ø© Ø¯ÙŠ      Distressed\n5        Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ÙˆØ­ÙŠØ¯ ÙˆØ¨Ø¹ÙŠØ¯ Ø¹Ù† ÙƒÙ„ Ø­Ø§Ø¬Ø©      Distressed\n6               Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ­ÙƒÙ… ÙÙŠ Ù…Ø´Ø§Ø¹Ø±ÙŠ      Distressed\n7          Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø­Ø§ØµØ± ÙˆÙ…Ø´ Ø¹Ø§Ø±Ù Ø£Ø·Ù„Ø¹      Distressed\n8            Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹Ø¨Ø± Ø¹Ù† Ø§Ù„Ù„ÙŠ Ø¬ÙˆØ§ÙŠØ§      Distressed\n9   Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ØªØ¹Ø¨Ø§Ù† Ù†ÙØ³ÙŠØ§Ù‹ ÙˆÙ…Ø´ Ù‚Ø§Ø¯Ø± Ø£ÙƒÙ…Ù„      Distressed\n10               Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø­Ø·Ù… Ù…Ù† Ø¬ÙˆØ§ÙŠØ§      Distressed\n11           Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ­Ù…Ù„ Ø§Ù„ÙˆØ¬Ø¹ Ø§Ù„Ù†ÙØ³ÙŠ      Distressed\n12     Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø³Ù„Ø¨ÙŠØ©      Distressed\n13             Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ ÙØ§Ø´Ù„ ÙÙŠ ÙƒÙ„ Ø­Ø§Ø¬Ø©      Distressed\n14          Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ø·Ù‰ Ø§Ù„Ù„ÙŠ Ù…Ø±ÙŠØª Ø¨ÙŠÙ‡      Distressed\n15                Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø¹ÙŠØ´      Distressed\n16               Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø³ÙŠØ·Ø± Ø¹Ù„Ù‰ Ù‚Ù„Ù‚ÙŠ      Distressed\n17      Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ÙŠÙ‚      Distressed\n18             Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø¥Ø­Ø¨Ø§Ø·      Distressed\n19                   Ø£Ù†Ø§ Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯      Distressed\n20                    Ø£Ù†Ø§ ÙƒÙˆÙŠØ³ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡  Non-distressed\n21             ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ ÙˆÙ…ÙÙŠØ´ Ø­Ø§Ø¬Ø© ØªÙ‚Ù„Ù‚  Non-distressed\n22                 Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù‡Ø§Ø¯ÙŠ ÙˆÙ…Ø±ÙŠØ­  Non-distressed\n23            Ø­Ø§Ø³Ø³ Ø¨Ø±Ø§Ø­Ø© ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡  Non-distressed\n24             Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø£Ù…Ù„ ÙˆÙØ±Ø­  Non-distressed\n25         Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ø¨Ø®ÙŠØ± ÙˆØ¨Ø¹ÙŠØ´ ÙŠÙˆÙ… Ø¬Ù…ÙŠÙ„  Non-distressed\n26      Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ø¹Ø§Ø¯ÙŠ ÙˆÙ…Ø´ Ø­Ø§Ø³Ø³ Ø¨Ø£ÙŠ Ø¶ØºØ·  Non-distressed\n27                Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· ÙˆÙ…Ø±ØªØ§Ø­  Non-distressed\n28         Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø·Ø§Ù‚Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©  Non-distressed\n29     Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù‚ÙˆÙŠ ÙˆÙ‚Ø§Ø¯Ø± Ø£ØªØ®Ø·Ù‰ Ø£ÙŠ Ø­Ø§Ø¬Ø©  Non-distressed\n30                Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† ØªÙØ§Ø¤Ù„  Non-distressed\n31          Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· Ø¨Ø§Ù„Ù„ÙŠ Ø­ÙˆØ§Ù„ÙŠØ§  Non-distressed\n32            Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø­Ø¨ ÙˆØ³Ø¹Ø§Ø¯Ø©  Non-distressed\n33                 Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø±ØªØ§Ø­ Ø§Ù„Ø¨Ø§Ù„  Non-distressed\n34         Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ù†Ø¬Ø§Ø­Ø§Øª ØµØºÙŠØ±Ø©  Non-distressed\n35            Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…ØªÙØ§Ø¦Ù„ Ø¨Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„  Non-distressed\n36          Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ù„Ø­Ø¸Ø§Øª Ø¬Ù…ÙŠÙ„Ø©  Non-distressed\n37               Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø¨Ø³ÙˆØ· Ø¨Ø§Ù„Ø­ÙŠØ§Ø©  Non-distressed\n38         Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† ØªÙØ§ØµÙŠÙ„ Ø³Ø¹ÙŠØ¯Ø©  Non-distressed\n39               Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø±ØªØ§Ø­ ÙˆÙ…ØªÙØ§Ø¦Ù„  Non-distressed\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers datasets torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:03.957340Z","iopub.execute_input":"2025-01-19T03:32:03.957607Z","iopub.status.idle":"2025-01-19T03:32:08.045607Z","shell.execute_reply.started":"2025-01-19T03:32:03.957573Z","shell.execute_reply":"2025-01-19T03:32:08.044727Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# ***Fine tuning BERT and using the Arabic BERT tokenizer***","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\n\ndf = pd.read_csv(\"sentiments_data.csv\")\n\n# Map string labels to numerical labels\nlabel_map = {\"Distressed\": 0, \"Non-distressed\": 1}\ndf[\"label\"] = df[\"label\"].map(label_map)\n\n# Convert to Hugging Face Dataset\ndataset = Dataset.from_pandas(df)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",  # Pad to max_length\n        truncation=True,       # Truncate to max_length\n        max_length=128,        # Set a fixed max_length\n    )\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Split the dataset into train and test sets\ntokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:08.047154Z","iopub.execute_input":"2025-01-19T03:32:08.047386Z","iopub.status.idle":"2025-01-19T03:32:30.010674Z","shell.execute_reply.started":"2025-01-19T03:32:08.047357Z","shell.execute_reply":"2025-01-19T03:32:30.010078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a760fff83ca42acb021f2c97e3bd65b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312f340bc0cd4918a9dff7ccf4fa8a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecadb3ac2eb2488eb24008b9e69c367b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae2cfaf8671d43ed99721fb27eec0517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b3a50f16404ff0b63a6830389911cb"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load the Tokenizer\n# When using BERT, traditional NLP preprocessing steps like stop word removal, stemming, lemmatization, or lowercasing are not required. Here's why:\n#\n# - BERT Tokenizer: The BERT tokenizer is designed to process raw text directly. It uses subword tokenization (e.g., WordPiece),\n#   which breaks words into smaller units, enabling it to handle out-of-vocabulary words and morphological variations effectively.\n#\n# - Stop Words: BERT is trained on large corpora and can inherently understand the importance (or lack thereof) of stop words in context.\n#   Removing stop words may harm performance, as BERT relies on the full context of the sentence.\n#\n# - Other Preprocessing: Steps like stemming, lemmatization, or lowercasing are unnecessary. BERT's tokenizer and model are optimized\n#   to work with raw text in its original form.\n#\n# Tokenize the Dataset\n# Simply pass your raw text directly to the BERT tokenizer. It will handle the tokenization process, ensuring the text is in the\n# optimal format for the model.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:30.011878Z","iopub.execute_input":"2025-01-19T03:32:30.012147Z","iopub.status.idle":"2025-01-19T03:32:30.015580Z","shell.execute_reply.started":"2025-01-19T03:32:30.012125Z","shell.execute_reply":"2025-01-19T03:32:30.014713Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"asafaya/bert-base-arabic\", num_labels=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:30.016503Z","iopub.execute_input":"2025-01-19T03:32:30.016835Z","iopub.status.idle":"2025-01-19T03:32:32.534239Z","shell.execute_reply.started":"2025-01-19T03:32:30.016803Z","shell.execute_reply":"2025-01-19T03:32:32.533602Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a626e675bb84e77b2ca4b067a980aae"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#make the code device agnostic\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:32.534977Z","iopub.execute_input":"2025-01-19T03:32:32.535272Z","iopub.status.idle":"2025-01-19T03:32:32.606428Z","shell.execute_reply.started":"2025-01-19T03:32:32.535249Z","shell.execute_reply":"2025-01-19T03:32:32.605707Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import TrainingArguments\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",  # Change to a valid directory\n    report_to=\"none\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    fp16=False,  # Disable mixed precision\n    disable_tqdm=False,\n    push_to_hub=False,\n    save_only_model=True,  # Save only the model\n    max_grad_norm=1.0,\n    seed=42\n)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:32.607183Z","iopub.execute_input":"2025-01-19T03:32:32.607563Z","iopub.status.idle":"2025-01-19T03:32:33.015418Z","shell.execute_reply.started":"2025-01-19T03:32:32.607526Z","shell.execute_reply":"2025-01-19T03:32:33.014656Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#functions used for metrics\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nfrom tqdm import tqdm\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n\n    accuracy = accuracy_score(labels, predictions)\n    precision = precision_score(labels, predictions, average=\"weighted\")\n    recall = recall_score(labels, predictions, average=\"weighted\")\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:33.017233Z","iopub.execute_input":"2025-01-19T03:32:33.017441Z","iopub.status.idle":"2025-01-19T03:32:33.022299Z","shell.execute_reply.started":"2025-01-19T03:32:33.017423Z","shell.execute_reply":"2025-01-19T03:32:33.021340Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:33.023662Z","iopub.execute_input":"2025-01-19T03:32:33.023951Z","iopub.status.idle":"2025-01-19T03:33:09.031659Z","shell.execute_reply.started":"2025-01-19T03:32:33.023921Z","shell.execute_reply":"2025-01-19T03:33:09.030970Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:33, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.678200</td>\n      <td>0.625000</td>\n      <td>0.812500</td>\n      <td>0.625000</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.660218</td>\n      <td>0.625000</td>\n      <td>0.812500</td>\n      <td>0.625000</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.611356</td>\n      <td>0.750000</td>\n      <td>0.850000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.565268</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.533409</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.478879</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.432122</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.387412</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.351669</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.467500</td>\n      <td>0.320856</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.467500</td>\n      <td>0.291434</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.467500</td>\n      <td>0.264426</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.467500</td>\n      <td>0.243424</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.467500</td>\n      <td>0.226857</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.467500</td>\n      <td>0.210932</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.467500</td>\n      <td>0.196789</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.467500</td>\n      <td>0.185568</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.467500</td>\n      <td>0.177531</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.467500</td>\n      <td>0.172488</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.156000</td>\n      <td>0.169985</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=20, training_loss=0.31171520948410036, metrics={'train_runtime': 35.6718, 'train_samples_per_second': 17.941, 'train_steps_per_second': 0.561, 'total_flos': 42097768857600.0, 'train_loss': 0.31171520948410036, 'epoch': 20.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"The model may be overfitting, but that is expected for how small the dataset is. Also, as this is a medical study, we need to focus on how good our model outputs the precision because precision measures the reliability of the model's positive predictions, and in medical contexts, false positives (incorrectly identifying a condition or distress) can lead to unnecessary treatments, increased healthcare costs, and psychological stress for patients. Therefore, ensuring high precision is critical to avoid these negative consequences and maintain trust in the model's predictions.\n","metadata":{}},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(f\"Evaluation results: {eval_results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:09.032370Z","iopub.execute_input":"2025-01-19T03:33:09.032587Z","iopub.status.idle":"2025-01-19T03:33:09.131422Z","shell.execute_reply.started":"2025-01-19T03:33:09.032568Z","shell.execute_reply":"2025-01-19T03:33:09.130788Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 0.16998469829559326, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.0918, 'eval_samples_per_second': 87.154, 'eval_steps_per_second': 10.894, 'epoch': 20.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get predictions on the evaluation dataset\npredictions = trainer.predict(tokenized_dataset[\"test\"])\n\n# Extract predicted labels and true labels\npredicted_labels = np.argmax(predictions.predictions, axis=-1)\ntrue_labels = predictions.label_ids\n\n# Compute the confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Display the confusion matrix\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n            xticklabels=[\"Distressed\", \"Non-distressed\"],\n            yticklabels=[\"Distressed\", \"Non-distressed\"])\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:09.132186Z","iopub.execute_input":"2025-01-19T03:33:09.132394Z","iopub.status.idle":"2025-01-19T03:33:16.615136Z","shell.execute_reply.started":"2025-01-19T03:33:09.132370Z","shell.execute_reply":"2025-01-19T03:33:16.614333Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#saving the model and the tokenizer\nmodel.save_pretrained(\"./fine-tuned-bert-arabic\")\ntokenizer.save_pretrained(\"./fine-tuned-bert-arabic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:16.615822Z","iopub.execute_input":"2025-01-19T03:33:16.616365Z","iopub.status.idle":"2025-01-19T03:33:19.640864Z","shell.execute_reply.started":"2025-01-19T03:33:16.616340Z","shell.execute_reply":"2025-01-19T03:33:19.640168Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned-bert-arabic/tokenizer_config.json',\n './fine-tuned-bert-arabic/special_tokens_map.json',\n './fine-tuned-bert-arabic/vocab.txt',\n './fine-tuned-bert-arabic/added_tokens.json',\n './fine-tuned-bert-arabic/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load the fine-tuned model\npredict_emotion = pipeline(\n    \"text-classification\",\n    model=\"./fine-tuned-bert-arabic\",\n    tokenizer=tokenizer,\n)\n\n# Define the reverse label mapping\nreverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}\n\n# Test on a new sentence\nresult = predict_emotion(\"Ø£Ù†Ø§ Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯\")\n\n# Unmap the numerical label to the string label\npredicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\nconfidence = result[0][\"score\"]\n\nprint(f\"Predicted Label: {predicted_label}\")\nprint(f\"Confidence: {confidence:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:19.641820Z","iopub.execute_input":"2025-01-19T03:33:19.642177Z","iopub.status.idle":"2025-01-19T03:33:21.510132Z","shell.execute_reply.started":"2025-01-19T03:33:19.642140Z","shell.execute_reply":"2025-01-19T03:33:21.509395Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Predicted Label: Distressed\nConfidence: 0.9121\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Test sentences\ntest_sentences = [\n    \"Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ø±Ø§Ø­Ø© Ø§Ù„ÙŠÙˆÙ…\",  # I feel happy and comfortable today\n    \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ù†Ø§Ù… Ù…Ù† Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„\",  # I can't sleep because of thinking about problems\n    \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø¥Ù†Ø¬Ø§Ø²Ø§Øª ÙˆØ£Ø´Ø¹Ø± Ø¨Ø§Ù„ÙØ®Ø±\",  # Today was full of achievements, and I feel proud\n    \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù†ÙØ³ÙŠ\",  # I feel like I can't breathe from the psychological pressure\n    \"ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ Ø¬Ø¯Ù‹Ø§ØŒ Ù…ÙÙŠØ´ Ø­Ø§Ø¬Ø© Ø¬Ø¯ÙŠØ¯Ø©\",  # A very ordinary day, nothing new\n    \"Ø£Ù†Ø§ Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯\"\n]\n\nfor sentence in test_sentences:\n    result = predict_emotion(sentence)\n    predicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\n    confidence = result[0][\"score\"]\n    print(f\"Text: {sentence}\")\n    print(f\"Predicted Label: {predicted_label}\")\n    print(f\"Confidence: {confidence:.4f}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:21.510895Z","iopub.execute_input":"2025-01-19T03:33:21.511143Z","iopub.status.idle":"2025-01-19T03:33:24.012630Z","shell.execute_reply.started":"2025-01-19T03:33:21.511122Z","shell.execute_reply":"2025-01-19T03:33:24.011861Z"}},"outputs":[{"name":"stdout","text":"Text: Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ø±Ø§Ø­Ø© Ø§Ù„ÙŠÙˆÙ…\nPredicted Label: Non-distressed\nConfidence: 0.8722\n\nText: Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ù†Ø§Ù… Ù…Ù† Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„\nPredicted Label: Distressed\nConfidence: 0.9157\n\nText: Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø¥Ù†Ø¬Ø§Ø²Ø§Øª ÙˆØ£Ø´Ø¹Ø± Ø¨Ø§Ù„ÙØ®Ø±\nPredicted Label: Non-distressed\nConfidence: 0.9602\n\nText: Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù†ÙØ³ÙŠ\nPredicted Label: Distressed\nConfidence: 0.9065\n\nText: ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ Ø¬Ø¯Ù‹Ø§ØŒ Ù…ÙÙŠØ´ Ø­Ø§Ø¬Ø© Ø¬Ø¯ÙŠØ¯Ø©\nPredicted Label: Non-distressed\nConfidence: 0.8768\n\nText: Ø£Ù†Ø§ Ø­Ø§Ø³Ø³ Ø¨Ø¶ÙŠÙ‚ Ø´Ø¯ÙŠØ¯\nPredicted Label: Distressed\nConfidence: 0.9121\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"you can uncomment and use this code to input an arabic sentence","metadata":{}},{"cell_type":"code","source":"# # Load the fine-tuned model and tokenizer\n# from transformers import pipeline\n\n# model_path = \"./fine_tuned_arabic_bert\"\n# classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)\n\n# # Define the reverse label map (if you have one)\n# reverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}  # Adjust based on your label mapping\n\n# # Function to classify user input\n# def classify_text():\n#     while True:\n#         # Take user input\n#         user_input = input(\"Enter a sentence in Arabic (or type 'exit' to quit): \")\n        \n#         # Exit condition\n#         if user_input.lower() == \"exit\":\n#             print(\"Exiting...\")\n#             break\n        \n#         # Classify the input\n#         result = classifier(user_input)\n#         predicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\n#         confidence = result[0][\"score\"]\n        \n#         # Print results\n#         print(f\"Text: {user_input}\")\n#         print(f\"Predicted Label: {predicted_label}\")\n#         print(f\"Confidence: {confidence:.4f}\")\n#         print()\n\n# # Run the classifier\n# classify_text()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.013341Z","iopub.execute_input":"2025-01-19T03:33:24.013629Z","iopub.status.idle":"2025-01-19T03:33:24.016867Z","shell.execute_reply.started":"2025-01-19T03:33:24.013606Z","shell.execute_reply":"2025-01-19T03:33:24.016107Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"why not do it simply as we don't have that many data points so let's run a quick xgboost algortihm ","metadata":{}},{"cell_type":"markdown","source":"# ***XGBOOST approach***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndf = pd.read_csv(\"sentiments_data.csv\")\n\n# Map string labels to numerical labels\nlabel_map = {\"Distressed\": 0, \"Non-distressed\": 1}\ndf[\"label\"] = df[\"label\"].map(label_map)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n\n# Convert text to TF-IDF features\nvectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Train XGBoost\nxgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\nxgb_model.fit(X_train_tfidf, y_train)\n\n# Evaluate the model\ny_pred = xgb_model.predict(X_test_tfidf)\n\n# Compute metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average=\"weighted\")\nrecall = recall_score(y_test, y_pred, average=\"weighted\")\nf1 = f1_score(y_test, y_pred, average=\"weighted\")\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.017821Z","iopub.execute_input":"2025-01-19T03:33:24.018109Z","iopub.status.idle":"2025-01-19T03:33:24.303564Z","shell.execute_reply.started":"2025-01-19T03:33:24.018076Z","shell.execute_reply":"2025-01-19T03:33:24.302833Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6250\nPrecision: 0.8125\nRecall: 0.6250\nF1 Score: 0.6071\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Test sentences\ntest_sentences = [\n    \"Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ø±Ø§Ø­Ø© Ø§Ù„ÙŠÙˆÙ…\",  # I feel happy and comfortable today\n    \"Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ù†Ø§Ù… Ù…Ù† Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„\",  # I can't sleep because of thinking about problems\n    \"Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø¥Ù†Ø¬Ø§Ø²Ø§Øª ÙˆØ£Ø´Ø¹Ø± Ø¨Ø§Ù„ÙØ®Ø±\",  # Today was full of achievements, and I feel proud\n    \"Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù†ÙØ³ÙŠ\",  # I feel like I can't breathe from the psychological pressure\n    \"ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ Ø¬Ø¯Ù‹Ø§ØŒ Ù…ÙÙŠØ´ Ø­Ø§Ø¬Ø© Ø¬Ø¯ÙŠØ¯Ø©\",  # A very ordinary day, nothing new\n]\n\n#reverse label mapping so we output the actual label not 1 or 0 \nreverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}\n\n# Transform the test sentences into TF-IDF features\ntest_sentences_tfidf = vectorizer.transform(test_sentences)\n\n# Predict\npredictions = xgb_model.predict(test_sentences_tfidf)\nprobabilities = xgb_model.predict_proba(test_sentences_tfidf)\n\n#results\nfor sentence, prediction, prob in zip(test_sentences, predictions, probabilities):\n    predicted_label = reverse_label_map[prediction]\n    confidence = prob[prediction]  # Confidence for the predicted class\n    print(f\"Text: {sentence}\")\n    print(f\"Predicted Label: {predicted_label}\")\n    print(f\"Confidence: {confidence:.4f}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.304468Z","iopub.execute_input":"2025-01-19T03:33:24.304782Z","iopub.status.idle":"2025-01-19T03:33:24.315407Z","shell.execute_reply.started":"2025-01-19T03:33:24.304751Z","shell.execute_reply":"2025-01-19T03:33:24.314510Z"}},"outputs":[{"name":"stdout","text":"Text: Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ø±Ø§Ø­Ø© Ø§Ù„ÙŠÙˆÙ…\nPredicted Label: Non-distressed\nConfidence: 0.7501\n\nText: Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ù†Ø§Ù… Ù…Ù† Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„\nPredicted Label: Distressed\nConfidence: 0.8859\n\nText: Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù…Ù„ÙŠØ§Ù† Ø¥Ù†Ø¬Ø§Ø²Ø§Øª ÙˆØ£Ø´Ø¹Ø± Ø¨Ø§Ù„ÙØ®Ø±\nPredicted Label: Non-distressed\nConfidence: 0.8788\n\nText: Ø­Ø§Ø³Ø³ Ø¥Ù†ÙŠ Ù…Ø´ Ø¹Ø§Ø±Ù Ø£ØªÙ†ÙØ³ Ù…Ù† Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù†ÙØ³ÙŠ\nPredicted Label: Distressed\nConfidence: 0.8876\n\nText: ÙŠÙˆÙ… Ø¹Ø§Ø¯ÙŠ Ø¬Ø¯Ù‹Ø§ØŒ Ù…ÙÙŠØ´ Ø­Ø§Ø¬Ø© Ø¬Ø¯ÙŠØ¯Ø©\nPredicted Label: Non-distressed\nConfidence: 0.7501\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}