{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First of all I will make my own synthetic data set to try on in arabic","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Data \n#create balanced data so no one label  overrules the others\ndata = [\n    {\"text\": \"أنا مخنوق ومش قادر أتنفس\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس بضيق شديد ومش لاقي أي أمل\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني ضايع ومحدش فاهمني\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أعيش كده كتير\", \"label\": \"Distressed\"},\n    {\"text\": \"مش قادر أواجه الحياة دي\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني وحيد وبعيد عن كل حاجة\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أتحكم في مشاعري\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني محاصر ومش عارف أطلع\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أعبر عن اللي جوايا\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني تعبان نفسياً ومش قادر أكمل\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني محطم من جوايا\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أتحمل الوجع النفسي\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أتخلص من الأفكار السلبية\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني فاشل في كل حاجة\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أتخطى اللي مريت بيه\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني مش عارف أعيش\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أسيطر على قلقي\", \"label\": \"Distressed\"},\n    {\"text\": \"حاسس إني مش عارف أتنفس من الضيق\", \"label\": \"Distressed\"},\n    {\"text\": \"مش عارف أتخلص من الإحباط\", \"label\": \"Distressed\"},\n    {\"text\": \"أنا حاسس بضيق شديد\", \"label\": \"Distressed\"},\n\n    # Non-distressed examples\n    {\"text\": \"أنا كويس النهارده\", \"label\": \"Non-distressed\"},\n    {\"text\": \"يوم عادي ومفيش حاجة تقلق\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان هادي ومريح\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس براحة كبيرة النهارده\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان أمل وفرح\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني بخير وبعيش يوم جميل\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان عادي ومش حاسس بأي ضغط\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني مبسوط ومرتاح\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان طاقة إيجابية\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني قوي وقادر أتخطى أي حاجة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان تفاؤل\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني مبسوط باللي حواليا\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان حب وسعادة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني مرتاح البال\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان نجاحات صغيرة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني متفائل بالمستقبل\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان لحظات جميلة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني مبسوط بالحياة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"اليوم كان مليان تفاصيل سعيدة\", \"label\": \"Non-distressed\"},\n    {\"text\": \"حاسس إني مرتاح ومتفائل\", \"label\": \"Non-distressed\"},\n]\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(df)\n\n\n# Save to CSV \ndf.to_csv(\"sentiments_data.csv\", index=False, encoding=\"utf-8-sig\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:03.570140Z","iopub.execute_input":"2025-01-19T03:32:03.570405Z","iopub.status.idle":"2025-01-19T03:32:03.956392Z","shell.execute_reply.started":"2025-01-19T03:32:03.570385Z","shell.execute_reply":"2025-01-19T03:32:03.955590Z"}},"outputs":[{"name":"stdout","text":"                                   text           label\n0              أنا مخنوق ومش قادر أتنفس      Distressed\n1        حاسس بضيق شديد ومش لاقي أي أمل      Distressed\n2            حاسس إني ضايع ومحدش فاهمني      Distressed\n3                 مش عارف أعيش كده كتير      Distressed\n4               مش قادر أواجه الحياة دي      Distressed\n5        حاسس إني وحيد وبعيد عن كل حاجة      Distressed\n6               مش عارف أتحكم في مشاعري      Distressed\n7          حاسس إني محاصر ومش عارف أطلع      Distressed\n8            مش عارف أعبر عن اللي جوايا      Distressed\n9   حاسس إني تعبان نفسياً ومش قادر أكمل      Distressed\n10               حاسس إني محطم من جوايا      Distressed\n11           مش عارف أتحمل الوجع النفسي      Distressed\n12     مش عارف أتخلص من الأفكار السلبية      Distressed\n13             حاسس إني فاشل في كل حاجة      Distressed\n14          مش عارف أتخطى اللي مريت بيه      Distressed\n15                حاسس إني مش عارف أعيش      Distressed\n16               مش عارف أسيطر على قلقي      Distressed\n17      حاسس إني مش عارف أتنفس من الضيق      Distressed\n18             مش عارف أتخلص من الإحباط      Distressed\n19                   أنا حاسس بضيق شديد      Distressed\n20                    أنا كويس النهارده  Non-distressed\n21             يوم عادي ومفيش حاجة تقلق  Non-distressed\n22                 اليوم كان هادي ومريح  Non-distressed\n23            حاسس براحة كبيرة النهارده  Non-distressed\n24             اليوم كان مليان أمل وفرح  Non-distressed\n25         حاسس إني بخير وبعيش يوم جميل  Non-distressed\n26      اليوم كان عادي ومش حاسس بأي ضغط  Non-distressed\n27                حاسس إني مبسوط ومرتاح  Non-distressed\n28         اليوم كان مليان طاقة إيجابية  Non-distressed\n29     حاسس إني قوي وقادر أتخطى أي حاجة  Non-distressed\n30                اليوم كان مليان تفاؤل  Non-distressed\n31          حاسس إني مبسوط باللي حواليا  Non-distressed\n32            اليوم كان مليان حب وسعادة  Non-distressed\n33                 حاسس إني مرتاح البال  Non-distressed\n34         اليوم كان مليان نجاحات صغيرة  Non-distressed\n35            حاسس إني متفائل بالمستقبل  Non-distressed\n36          اليوم كان مليان لحظات جميلة  Non-distressed\n37               حاسس إني مبسوط بالحياة  Non-distressed\n38         اليوم كان مليان تفاصيل سعيدة  Non-distressed\n39               حاسس إني مرتاح ومتفائل  Non-distressed\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers datasets torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:03.957340Z","iopub.execute_input":"2025-01-19T03:32:03.957607Z","iopub.status.idle":"2025-01-19T03:32:08.045607Z","shell.execute_reply.started":"2025-01-19T03:32:03.957573Z","shell.execute_reply":"2025-01-19T03:32:08.044727Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# ***Fine tuning BERT and using the Arabic BERT tokenizer***","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\n\ndf = pd.read_csv(\"sentiments_data.csv\")\n\n# Map string labels to numerical labels\nlabel_map = {\"Distressed\": 0, \"Non-distressed\": 1}\ndf[\"label\"] = df[\"label\"].map(label_map)\n\n# Convert to Hugging Face Dataset\ndataset = Dataset.from_pandas(df)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",  # Pad to max_length\n        truncation=True,       # Truncate to max_length\n        max_length=128,        # Set a fixed max_length\n    )\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Split the dataset into train and test sets\ntokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:08.047154Z","iopub.execute_input":"2025-01-19T03:32:08.047386Z","iopub.status.idle":"2025-01-19T03:32:30.010674Z","shell.execute_reply.started":"2025-01-19T03:32:08.047357Z","shell.execute_reply":"2025-01-19T03:32:30.010078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a760fff83ca42acb021f2c97e3bd65b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312f340bc0cd4918a9dff7ccf4fa8a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecadb3ac2eb2488eb24008b9e69c367b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae2cfaf8671d43ed99721fb27eec0517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b3a50f16404ff0b63a6830389911cb"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load the Tokenizer\n# When using BERT, traditional NLP preprocessing steps like stop word removal, stemming, lemmatization, or lowercasing are not required. Here's why:\n#\n# - BERT Tokenizer: The BERT tokenizer is designed to process raw text directly. It uses subword tokenization (e.g., WordPiece),\n#   which breaks words into smaller units, enabling it to handle out-of-vocabulary words and morphological variations effectively.\n#\n# - Stop Words: BERT is trained on large corpora and can inherently understand the importance (or lack thereof) of stop words in context.\n#   Removing stop words may harm performance, as BERT relies on the full context of the sentence.\n#\n# - Other Preprocessing: Steps like stemming, lemmatization, or lowercasing are unnecessary. BERT's tokenizer and model are optimized\n#   to work with raw text in its original form.\n#\n# Tokenize the Dataset\n# Simply pass your raw text directly to the BERT tokenizer. It will handle the tokenization process, ensuring the text is in the\n# optimal format for the model.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:30.011878Z","iopub.execute_input":"2025-01-19T03:32:30.012147Z","iopub.status.idle":"2025-01-19T03:32:30.015580Z","shell.execute_reply.started":"2025-01-19T03:32:30.012125Z","shell.execute_reply":"2025-01-19T03:32:30.014713Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"asafaya/bert-base-arabic\", num_labels=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:30.016503Z","iopub.execute_input":"2025-01-19T03:32:30.016835Z","iopub.status.idle":"2025-01-19T03:32:32.534239Z","shell.execute_reply.started":"2025-01-19T03:32:30.016803Z","shell.execute_reply":"2025-01-19T03:32:32.533602Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a626e675bb84e77b2ca4b067a980aae"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#make the code device agnostic\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:32.534977Z","iopub.execute_input":"2025-01-19T03:32:32.535272Z","iopub.status.idle":"2025-01-19T03:32:32.606428Z","shell.execute_reply.started":"2025-01-19T03:32:32.535249Z","shell.execute_reply":"2025-01-19T03:32:32.605707Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import TrainingArguments\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",  # Change to a valid directory\n    report_to=\"none\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    fp16=False,  # Disable mixed precision\n    disable_tqdm=False,\n    push_to_hub=False,\n    save_only_model=True,  # Save only the model\n    max_grad_norm=1.0,\n    seed=42\n)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:32.607183Z","iopub.execute_input":"2025-01-19T03:32:32.607563Z","iopub.status.idle":"2025-01-19T03:32:33.015418Z","shell.execute_reply.started":"2025-01-19T03:32:32.607526Z","shell.execute_reply":"2025-01-19T03:32:33.014656Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#functions used for metrics\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nfrom tqdm import tqdm\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n\n    accuracy = accuracy_score(labels, predictions)\n    precision = precision_score(labels, predictions, average=\"weighted\")\n    recall = recall_score(labels, predictions, average=\"weighted\")\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:33.017233Z","iopub.execute_input":"2025-01-19T03:32:33.017441Z","iopub.status.idle":"2025-01-19T03:32:33.022299Z","shell.execute_reply.started":"2025-01-19T03:32:33.017423Z","shell.execute_reply":"2025-01-19T03:32:33.021340Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:32:33.023662Z","iopub.execute_input":"2025-01-19T03:32:33.023951Z","iopub.status.idle":"2025-01-19T03:33:09.031659Z","shell.execute_reply.started":"2025-01-19T03:32:33.023921Z","shell.execute_reply":"2025-01-19T03:33:09.030970Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:33, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.678200</td>\n      <td>0.625000</td>\n      <td>0.812500</td>\n      <td>0.625000</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.660218</td>\n      <td>0.625000</td>\n      <td>0.812500</td>\n      <td>0.625000</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.611356</td>\n      <td>0.750000</td>\n      <td>0.850000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.565268</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.533409</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.478879</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.432122</td>\n      <td>0.875000</td>\n      <td>0.895833</td>\n      <td>0.875000</td>\n      <td>0.868182</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.387412</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.351669</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.467500</td>\n      <td>0.320856</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.467500</td>\n      <td>0.291434</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.467500</td>\n      <td>0.264426</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.467500</td>\n      <td>0.243424</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.467500</td>\n      <td>0.226857</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.467500</td>\n      <td>0.210932</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.467500</td>\n      <td>0.196789</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.467500</td>\n      <td>0.185568</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.467500</td>\n      <td>0.177531</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.467500</td>\n      <td>0.172488</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.156000</td>\n      <td>0.169985</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=20, training_loss=0.31171520948410036, metrics={'train_runtime': 35.6718, 'train_samples_per_second': 17.941, 'train_steps_per_second': 0.561, 'total_flos': 42097768857600.0, 'train_loss': 0.31171520948410036, 'epoch': 20.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"The model may be overfitting, but that is expected for how small the dataset is. Also, as this is a medical study, we need to focus on how good our model outputs the precision because precision measures the reliability of the model's positive predictions, and in medical contexts, false positives (incorrectly identifying a condition or distress) can lead to unnecessary treatments, increased healthcare costs, and psychological stress for patients. Therefore, ensuring high precision is critical to avoid these negative consequences and maintain trust in the model's predictions.\n","metadata":{}},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(f\"Evaluation results: {eval_results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:09.032370Z","iopub.execute_input":"2025-01-19T03:33:09.032587Z","iopub.status.idle":"2025-01-19T03:33:09.131422Z","shell.execute_reply.started":"2025-01-19T03:33:09.032568Z","shell.execute_reply":"2025-01-19T03:33:09.130788Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 0.16998469829559326, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.0918, 'eval_samples_per_second': 87.154, 'eval_steps_per_second': 10.894, 'epoch': 20.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get predictions on the evaluation dataset\npredictions = trainer.predict(tokenized_dataset[\"test\"])\n\n# Extract predicted labels and true labels\npredicted_labels = np.argmax(predictions.predictions, axis=-1)\ntrue_labels = predictions.label_ids\n\n# Compute the confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Display the confusion matrix\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n            xticklabels=[\"Distressed\", \"Non-distressed\"],\n            yticklabels=[\"Distressed\", \"Non-distressed\"])\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:09.132186Z","iopub.execute_input":"2025-01-19T03:33:09.132394Z","iopub.status.idle":"2025-01-19T03:33:16.615136Z","shell.execute_reply.started":"2025-01-19T03:33:09.132370Z","shell.execute_reply":"2025-01-19T03:33:16.614333Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#saving the model and the tokenizer\nmodel.save_pretrained(\"./fine-tuned-bert-arabic\")\ntokenizer.save_pretrained(\"./fine-tuned-bert-arabic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:16.615822Z","iopub.execute_input":"2025-01-19T03:33:16.616365Z","iopub.status.idle":"2025-01-19T03:33:19.640864Z","shell.execute_reply.started":"2025-01-19T03:33:16.616340Z","shell.execute_reply":"2025-01-19T03:33:19.640168Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned-bert-arabic/tokenizer_config.json',\n './fine-tuned-bert-arabic/special_tokens_map.json',\n './fine-tuned-bert-arabic/vocab.txt',\n './fine-tuned-bert-arabic/added_tokens.json',\n './fine-tuned-bert-arabic/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load the fine-tuned model\npredict_emotion = pipeline(\n    \"text-classification\",\n    model=\"./fine-tuned-bert-arabic\",\n    tokenizer=tokenizer,\n)\n\n# Define the reverse label mapping\nreverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}\n\n# Test on a new sentence\nresult = predict_emotion(\"أنا حاسس بضيق شديد\")\n\n# Unmap the numerical label to the string label\npredicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\nconfidence = result[0][\"score\"]\n\nprint(f\"Predicted Label: {predicted_label}\")\nprint(f\"Confidence: {confidence:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:19.641820Z","iopub.execute_input":"2025-01-19T03:33:19.642177Z","iopub.status.idle":"2025-01-19T03:33:21.510132Z","shell.execute_reply.started":"2025-01-19T03:33:19.642140Z","shell.execute_reply":"2025-01-19T03:33:21.509395Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Predicted Label: Distressed\nConfidence: 0.9121\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Test sentences\ntest_sentences = [\n    \"أشعر بالسعادة والراحة اليوم\",  # I feel happy and comfortable today\n    \"مش عارف أنام من التفكير في المشاكل\",  # I can't sleep because of thinking about problems\n    \"اليوم كان مليان إنجازات وأشعر بالفخر\",  # Today was full of achievements, and I feel proud\n    \"حاسس إني مش عارف أتنفس من الضغط النفسي\",  # I feel like I can't breathe from the psychological pressure\n    \"يوم عادي جدًا، مفيش حاجة جديدة\",  # A very ordinary day, nothing new\n    \"أنا حاسس بضيق شديد\"\n]\n\nfor sentence in test_sentences:\n    result = predict_emotion(sentence)\n    predicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\n    confidence = result[0][\"score\"]\n    print(f\"Text: {sentence}\")\n    print(f\"Predicted Label: {predicted_label}\")\n    print(f\"Confidence: {confidence:.4f}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:21.510895Z","iopub.execute_input":"2025-01-19T03:33:21.511143Z","iopub.status.idle":"2025-01-19T03:33:24.012630Z","shell.execute_reply.started":"2025-01-19T03:33:21.511122Z","shell.execute_reply":"2025-01-19T03:33:24.011861Z"}},"outputs":[{"name":"stdout","text":"Text: أشعر بالسعادة والراحة اليوم\nPredicted Label: Non-distressed\nConfidence: 0.8722\n\nText: مش عارف أنام من التفكير في المشاكل\nPredicted Label: Distressed\nConfidence: 0.9157\n\nText: اليوم كان مليان إنجازات وأشعر بالفخر\nPredicted Label: Non-distressed\nConfidence: 0.9602\n\nText: حاسس إني مش عارف أتنفس من الضغط النفسي\nPredicted Label: Distressed\nConfidence: 0.9065\n\nText: يوم عادي جدًا، مفيش حاجة جديدة\nPredicted Label: Non-distressed\nConfidence: 0.8768\n\nText: أنا حاسس بضيق شديد\nPredicted Label: Distressed\nConfidence: 0.9121\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"you can uncomment and use this code to input an arabic sentence","metadata":{}},{"cell_type":"code","source":"# # Load the fine-tuned model and tokenizer\n# from transformers import pipeline\n\n# model_path = \"./fine_tuned_arabic_bert\"\n# classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)\n\n# # Define the reverse label map (if you have one)\n# reverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}  # Adjust based on your label mapping\n\n# # Function to classify user input\n# def classify_text():\n#     while True:\n#         # Take user input\n#         user_input = input(\"Enter a sentence in Arabic (or type 'exit' to quit): \")\n        \n#         # Exit condition\n#         if user_input.lower() == \"exit\":\n#             print(\"Exiting...\")\n#             break\n        \n#         # Classify the input\n#         result = classifier(user_input)\n#         predicted_label = reverse_label_map[int(result[0][\"label\"].split(\"_\")[1])]\n#         confidence = result[0][\"score\"]\n        \n#         # Print results\n#         print(f\"Text: {user_input}\")\n#         print(f\"Predicted Label: {predicted_label}\")\n#         print(f\"Confidence: {confidence:.4f}\")\n#         print()\n\n# # Run the classifier\n# classify_text()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.013341Z","iopub.execute_input":"2025-01-19T03:33:24.013629Z","iopub.status.idle":"2025-01-19T03:33:24.016867Z","shell.execute_reply.started":"2025-01-19T03:33:24.013606Z","shell.execute_reply":"2025-01-19T03:33:24.016107Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"why not do it simply as we don't have that many data points so let's run a quick xgboost algortihm ","metadata":{}},{"cell_type":"markdown","source":"# ***XGBOOST approach***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndf = pd.read_csv(\"sentiments_data.csv\")\n\n# Map string labels to numerical labels\nlabel_map = {\"Distressed\": 0, \"Non-distressed\": 1}\ndf[\"label\"] = df[\"label\"].map(label_map)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n\n# Convert text to TF-IDF features\nvectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Train XGBoost\nxgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\nxgb_model.fit(X_train_tfidf, y_train)\n\n# Evaluate the model\ny_pred = xgb_model.predict(X_test_tfidf)\n\n# Compute metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average=\"weighted\")\nrecall = recall_score(y_test, y_pred, average=\"weighted\")\nf1 = f1_score(y_test, y_pred, average=\"weighted\")\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.017821Z","iopub.execute_input":"2025-01-19T03:33:24.018109Z","iopub.status.idle":"2025-01-19T03:33:24.303564Z","shell.execute_reply.started":"2025-01-19T03:33:24.018076Z","shell.execute_reply":"2025-01-19T03:33:24.302833Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6250\nPrecision: 0.8125\nRecall: 0.6250\nF1 Score: 0.6071\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Test sentences\ntest_sentences = [\n    \"أشعر بالسعادة والراحة اليوم\",  # I feel happy and comfortable today\n    \"مش عارف أنام من التفكير في المشاكل\",  # I can't sleep because of thinking about problems\n    \"اليوم كان مليان إنجازات وأشعر بالفخر\",  # Today was full of achievements, and I feel proud\n    \"حاسس إني مش عارف أتنفس من الضغط النفسي\",  # I feel like I can't breathe from the psychological pressure\n    \"يوم عادي جدًا، مفيش حاجة جديدة\",  # A very ordinary day, nothing new\n]\n\n#reverse label mapping so we output the actual label not 1 or 0 \nreverse_label_map = {0: \"Distressed\", 1: \"Non-distressed\"}\n\n# Transform the test sentences into TF-IDF features\ntest_sentences_tfidf = vectorizer.transform(test_sentences)\n\n# Predict\npredictions = xgb_model.predict(test_sentences_tfidf)\nprobabilities = xgb_model.predict_proba(test_sentences_tfidf)\n\n#results\nfor sentence, prediction, prob in zip(test_sentences, predictions, probabilities):\n    predicted_label = reverse_label_map[prediction]\n    confidence = prob[prediction]  # Confidence for the predicted class\n    print(f\"Text: {sentence}\")\n    print(f\"Predicted Label: {predicted_label}\")\n    print(f\"Confidence: {confidence:.4f}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T03:33:24.304468Z","iopub.execute_input":"2025-01-19T03:33:24.304782Z","iopub.status.idle":"2025-01-19T03:33:24.315407Z","shell.execute_reply.started":"2025-01-19T03:33:24.304751Z","shell.execute_reply":"2025-01-19T03:33:24.314510Z"}},"outputs":[{"name":"stdout","text":"Text: أشعر بالسعادة والراحة اليوم\nPredicted Label: Non-distressed\nConfidence: 0.7501\n\nText: مش عارف أنام من التفكير في المشاكل\nPredicted Label: Distressed\nConfidence: 0.8859\n\nText: اليوم كان مليان إنجازات وأشعر بالفخر\nPredicted Label: Non-distressed\nConfidence: 0.8788\n\nText: حاسس إني مش عارف أتنفس من الضغط النفسي\nPredicted Label: Distressed\nConfidence: 0.8876\n\nText: يوم عادي جدًا، مفيش حاجة جديدة\nPredicted Label: Non-distressed\nConfidence: 0.7501\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}